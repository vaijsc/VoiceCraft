{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def create_subset_dataset(df, min_duration=0.3, max_duration=1.0):\n",
    "    # Load the metadata file into a DataFrame\n",
    "    # cols = ['filename', 'transcript', 'speaker', 'duration']\n",
    "    # df = pd.read_csv(metadata_path, sep='|', names=cols, header=None)\n",
    "\n",
    "    # Convert duration from seconds to hours\n",
    "    df['duration_hours'] = df['duration'] / 3600\n",
    "\n",
    "    # Group by speaker and calculate total duration\n",
    "    grouped = df.groupby('speaker')['duration_hours'].sum().reset_index()\n",
    "    \n",
    "    # Filter speakers based on the duration range\n",
    "    valid_speakers = grouped[(grouped['duration_hours'] >= min_duration) & (grouped['duration_hours'] <= max_duration)]['speaker']\n",
    "    filtered_df = df[df['speaker'].isin(valid_speakers)]\n",
    "\n",
    "    # Handle speakers with more than max_duration hours of audio\n",
    "    excessive_speakers = grouped[grouped['duration_hours'] > max_duration]['speaker']\n",
    "\n",
    "    for speaker in excessive_speakers:\n",
    "        speaker_df = df[df['speaker'] == speaker]\n",
    "        total_duration = speaker_df['duration_hours'].sum()\n",
    "        \n",
    "        while total_duration > max_duration:\n",
    "            # Randomly remove a file\n",
    "            to_remove = random.choice(speaker_df.index)\n",
    "            total_duration -= speaker_df.loc[to_remove, 'duration_hours']\n",
    "            speaker_df = speaker_df.drop(to_remove)\n",
    "        \n",
    "        filtered_df = pd.concat([filtered_df, speaker_df])\n",
    "\n",
    "    # Save the final list of files to the output CSV file\n",
    "    # filtered_df.drop(columns=['duration_hours'], inplace=True)\n",
    "    # filtered_df.to_csv(output_path, sep='|', index=False, header=False)\n",
    "\n",
    "    # print(f\"Subset dataset saved to {output_path}\")\n",
    "    return filtered_df\n",
    "\n",
    "# Example usage\n",
    "metadata_path = \"step14_tone_norm_transcript_no_multispeaker.txt\"\n",
    "output_path = \"filtered_sach_noi_0.1_1h.txt\"\n",
    "# filtered_df = create_subset_dataset(metadata_path, output_path, min_duration=0.0, max_duration=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# long audio\n",
    "metadata_path = \"step14_tone_norm_transcript_no_multispeaker.txt\"\n",
    "\n",
    "# short audio to augment the dataset\n",
    "# metadata_path = '/home/thivux/code/vinai/zstts/split_long_audio/metadata/step17_short_audio_wer0.csv'\n",
    "cols = ['filename', 'transcript', 'speaker', 'duration', 'wer']\n",
    "df = pd.read_csv(metadata_path, sep='|', names=cols, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1453.4473558427776"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['duration'].sum() / 3600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create test data\n",
    "\n",
    "top 20 speakers that speak the least will go to test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_speakers = [\n",
    "    'Huỳnh_Minh_Hiền', 'Lê_Á_Thi', 'Hoàng_Tín', 'Chủ_Tịch_Hồ_Chí_Minh',\n",
    "    'Nguyễn_Đình_Khánh', 'Thanh_Vân', '50_Nghệ_Sĩ-27-Huu Chau', 'BBC',\n",
    "    'Thy_Lan', 'Nam_Anh', 'Nguyễn_Ngọc', '50_Nghệ_Sĩ-15-Ly Hung',\n",
    "    'Thích_Chân_Tính', 'Hoàng_Mến', '50_Nghệ_Sĩ-39-Thai Hoa', '50_Nghệ_Sĩ',\n",
    "    '50_Nghệ_Sĩ-10-Do Trung Quan', 'Hải_Khuê', '50_Nghệ_Sĩ-36-Tang Thanh Ha',\n",
    "    'Lê_Bảo_Quốc'\n",
    "]\n",
    "\n",
    "test_df = df[df['speaker'].isin(test_speakers)]\n",
    "\n",
    "train_df = df[~df['speaker'].isin(test_speakers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.653989983333336"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['duration'].sum() / 60 # 0.4 hour\n",
    "# drop the 'wer' column \n",
    "# test_df.drop(columns=['wer'], inplace=True)\n",
    "# test_df.to_csv(metadata_path.replace('.csv', '_test.csv'), sep='|', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>transcript</th>\n",
       "      <th>speaker</th>\n",
       "      <th>duration</th>\n",
       "      <th>wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>big_processed_data/Nguyễn_Văn_Khỏa/Thần_Thoại_...</td>\n",
       "      <td>tôn kính thần linh. hay là họ là những con ngư...</td>\n",
       "      <td>Nguyễn_Văn_Khỏa</td>\n",
       "      <td>12.998563</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>big_processed_data/Nguyễn_Văn_Khỏa/Thần_Thoại_...</td>\n",
       "      <td>không phải là người biết ăn bánh mì. chúng sốn...</td>\n",
       "      <td>Nguyễn_Văn_Khỏa</td>\n",
       "      <td>11.391688</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>big_processed_data/Nguyễn_Văn_Khỏa/Thần_Thoại_...</td>\n",
       "      <td>ta sẽ chẳng xin phúc tha cho mày và đồng bọn c...</td>\n",
       "      <td>Nguyễn_Văn_Khỏa</td>\n",
       "      <td>10.878250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>big_processed_data/Nguyễn_Văn_Khỏa/Thần_Thoại_...</td>\n",
       "      <td>từ ngoài khơi. khi con thuyền đã cần cập bến n...</td>\n",
       "      <td>Nguyễn_Văn_Khỏa</td>\n",
       "      <td>10.393875</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>big_processed_data/Nguyễn_Văn_Khỏa/Thần_Thoại_...</td>\n",
       "      <td>giết chết hắn rồi, nhưng làm sao mà vần được c...</td>\n",
       "      <td>Nguyễn_Văn_Khỏa</td>\n",
       "      <td>10.795188</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  big_processed_data/Nguyễn_Văn_Khỏa/Thần_Thoại_...   \n",
       "1  big_processed_data/Nguyễn_Văn_Khỏa/Thần_Thoại_...   \n",
       "2  big_processed_data/Nguyễn_Văn_Khỏa/Thần_Thoại_...   \n",
       "3  big_processed_data/Nguyễn_Văn_Khỏa/Thần_Thoại_...   \n",
       "4  big_processed_data/Nguyễn_Văn_Khỏa/Thần_Thoại_...   \n",
       "\n",
       "                                          transcript          speaker  \\\n",
       "0  tôn kính thần linh. hay là họ là những con ngư...  Nguyễn_Văn_Khỏa   \n",
       "1  không phải là người biết ăn bánh mì. chúng sốn...  Nguyễn_Văn_Khỏa   \n",
       "2  ta sẽ chẳng xin phúc tha cho mày và đồng bọn c...  Nguyễn_Văn_Khỏa   \n",
       "3  từ ngoài khơi. khi con thuyền đã cần cập bến n...  Nguyễn_Văn_Khỏa   \n",
       "4  giết chết hắn rồi, nhưng làm sao mà vần được c...  Nguyễn_Văn_Khỏa   \n",
       "\n",
       "    duration  wer  \n",
       "0  12.998563  NaN  \n",
       "1  11.391688  NaN  \n",
       "2  10.878250  NaN  \n",
       "3  10.393875  NaN  \n",
       "4  10.795188  NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56430/4059279811.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop(columns=['wer'], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1453.0531226763887"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.drop(columns=['wer'], inplace=True)\n",
    "train_df.head()\n",
    "# train_df.to_csv(metadata_path.replace('.csv', '_train.csv'), sep='|', index=False, header=False)\n",
    "train_df['duration'].sum() / 3600 # 1453 hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56430/22099980.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['duration_hours'] = df['duration'] / 3600\n"
     ]
    }
   ],
   "source": [
    "filtered_train = create_subset_dataset(train_df, min_duration=0.0, max_duration=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "939.9035293661113"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train['duration'].sum() / 3600 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>duration_hours</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speaker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50_Nghệ_Sĩ-01-Quyen Linh</th>\n",
       "      <td>0.069887</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50_Nghệ_Sĩ-02-Ngo Thanh Van</th>\n",
       "      <td>0.045821</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50_Nghệ_Sĩ-03-Thien Ly</th>\n",
       "      <td>0.036944</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50_Nghệ_Sĩ-04-Dam Vinh Hung</th>\n",
       "      <td>0.035599</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50_Nghệ_Sĩ-05-Trung Dung</th>\n",
       "      <td>0.031720</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Đỗ_Thụy</th>\n",
       "      <td>1.124952</td>\n",
       "      <td>0.000312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Độc_Thám_TV</th>\n",
       "      <td>2.449838</td>\n",
       "      <td>0.000681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Đức_Huy</th>\n",
       "      <td>0.566308</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Đức_Trọng</th>\n",
       "      <td>1.068481</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Đức_Uy</th>\n",
       "      <td>1.541726</td>\n",
       "      <td>0.000428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>715 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             duration  duration_hours\n",
       "speaker                                              \n",
       "50_Nghệ_Sĩ-01-Quyen Linh     0.069887        0.000019\n",
       "50_Nghệ_Sĩ-02-Ngo Thanh Van  0.045821        0.000013\n",
       "50_Nghệ_Sĩ-03-Thien Ly       0.036944        0.000010\n",
       "50_Nghệ_Sĩ-04-Dam Vinh Hung  0.035599        0.000010\n",
       "50_Nghệ_Sĩ-05-Trung Dung     0.031720        0.000009\n",
       "...                               ...             ...\n",
       "Đỗ_Thụy                      1.124952        0.000312\n",
       "Độc_Thám_TV                  2.449838        0.000681\n",
       "Đức_Huy                      0.566308        0.000157\n",
       "Đức_Trọng                    1.068481        0.000297\n",
       "Đức_Uy                       1.541726        0.000428\n",
       "\n",
       "[715 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_speakers = filtered_train.groupby('speaker').sum('duration') / 3600\n",
    "train_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>transcript</th>\n",
       "      <th>speaker</th>\n",
       "      <th>duration</th>\n",
       "      <th>wer</th>\n",
       "      <th>duration_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>big_processed_data/Lê_Đức_Quân/Đối_Thoại_Với_M...</td>\n",
       "      <td>nó sẽ đi thôi.</td>\n",
       "      <td>Lê_Đức_Quân</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>big_processed_data/Nguyễn_Văn_Khỏa/Thần_Thoại_...</td>\n",
       "      <td>chúng đem bán, mỗi người mỗi nơi</td>\n",
       "      <td>Nguyễn_Văn_Khỏa</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>big_processed_data/Meredith_Mclver/Trump_101:_...</td>\n",
       "      <td>tuy nhiên, ở nơi làm việc, sự an toàn sẽ kìm h...</td>\n",
       "      <td>Meredith_Mclver</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>big_processed_data/Phúc_Lâm/Sức_Mạnh_Của_Động_...</td>\n",
       "      <td>mà chính họ gặp phải thông qua phương pháp này.</td>\n",
       "      <td>Phúc_Lâm</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>big_processed_data/Diễm_Hân/Nhân_Tố_Enzyme/nha...</td>\n",
       "      <td>nhưng khi cho thêm vào nước thì một lượng lớn ...</td>\n",
       "      <td>Diễm_Hân</td>\n",
       "      <td>5.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  big_processed_data/Lê_Đức_Quân/Đối_Thoại_Với_M...   \n",
       "1  big_processed_data/Nguyễn_Văn_Khỏa/Thần_Thoại_...   \n",
       "2  big_processed_data/Meredith_Mclver/Trump_101:_...   \n",
       "3  big_processed_data/Phúc_Lâm/Sức_Mạnh_Của_Động_...   \n",
       "4  big_processed_data/Diễm_Hân/Nhân_Tố_Enzyme/nha...   \n",
       "\n",
       "                                          transcript          speaker  \\\n",
       "0                                     nó sẽ đi thôi.      Lê_Đức_Quân   \n",
       "1                   chúng đem bán, mỗi người mỗi nơi  Nguyễn_Văn_Khỏa   \n",
       "2  tuy nhiên, ở nơi làm việc, sự an toàn sẽ kìm h...  Meredith_Mclver   \n",
       "3    mà chính họ gặp phải thông qua phương pháp này.         Phúc_Lâm   \n",
       "4  nhưng khi cho thêm vào nước thì một lượng lớn ...         Diễm_Hân   \n",
       "\n",
       "   duration  wer  duration_hours  \n",
       "0      1.36  0.0        0.000378  \n",
       "1      2.90  0.0        0.000806  \n",
       "2      3.77  0.0        0.001047  \n",
       "3      2.94  0.0        0.000817  \n",
       "4      5.48  0.0        0.001522  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>transcript</th>\n",
       "      <th>speaker</th>\n",
       "      <th>duration</th>\n",
       "      <th>wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>753292</th>\n",
       "      <td>big_processed_data/50_Nghệ_Sĩ/50_Nghệ_Sĩ_Đọc_“...</td>\n",
       "      <td>cho nên</td>\n",
       "      <td>50_Nghệ_Sĩ</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753295</th>\n",
       "      <td>big_processed_data/50_Nghệ_Sĩ/50_Nghệ_Sĩ_Đọc_“...</td>\n",
       "      <td>bi quan, chán nản,</td>\n",
       "      <td>50_Nghệ_Sĩ</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753296</th>\n",
       "      <td>big_processed_data/50_Nghệ_Sĩ/50_Nghệ_Sĩ_Đọc_“...</td>\n",
       "      <td>thì họ sẽ được cứu rỗi về một thế giới chỉ toà...</td>\n",
       "      <td>50_Nghệ_Sĩ</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753297</th>\n",
       "      <td>big_processed_data/50_Nghệ_Sĩ/50_Nghệ_Sĩ_Đọc_“...</td>\n",
       "      <td>cũng là một kiểu mê tín.</td>\n",
       "      <td>50_Nghệ_Sĩ</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753298</th>\n",
       "      <td>big_processed_data/50_Nghệ_Sĩ/50_Nghệ_Sĩ_Đọc_“...</td>\n",
       "      <td>đó là bởi ta không biết</td>\n",
       "      <td>50_Nghệ_Sĩ</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 filename  \\\n",
       "753292  big_processed_data/50_Nghệ_Sĩ/50_Nghệ_Sĩ_Đọc_“...   \n",
       "753295  big_processed_data/50_Nghệ_Sĩ/50_Nghệ_Sĩ_Đọc_“...   \n",
       "753296  big_processed_data/50_Nghệ_Sĩ/50_Nghệ_Sĩ_Đọc_“...   \n",
       "753297  big_processed_data/50_Nghệ_Sĩ/50_Nghệ_Sĩ_Đọc_“...   \n",
       "753298  big_processed_data/50_Nghệ_Sĩ/50_Nghệ_Sĩ_Đọc_“...   \n",
       "\n",
       "                                               transcript     speaker  \\\n",
       "753292                                            cho nên  50_Nghệ_Sĩ   \n",
       "753295                                 bi quan, chán nản,  50_Nghệ_Sĩ   \n",
       "753296  thì họ sẽ được cứu rỗi về một thế giới chỉ toà...  50_Nghệ_Sĩ   \n",
       "753297                           cũng là một kiểu mê tín.  50_Nghệ_Sĩ   \n",
       "753298                            đó là bởi ta không biết  50_Nghệ_Sĩ   \n",
       "\n",
       "        duration  wer  \n",
       "753292      1.26  0.0  \n",
       "753295      1.20  0.0  \n",
       "753296      3.90  0.0  \n",
       "753297      2.06  0.0  \n",
       "753298      2.52  0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat filtered_train & test_df and save to txt file \n",
    "filtered_df = pd.concat([filtered_train, test_df], ignore_index=True)\n",
    "df_to_save = filtered_df.drop(columns=['duration_hours'])\n",
    "# df_to_save.to_csv(\"step16_cap_speaker_length_940h.txt\", sep='|', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "554.1057833333332"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['duration'].sum() / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train & test to separate files\n",
    "filtered_train.to_csv(\"step16_cap_speaker_length_940h_train.txt\", sep='|', index=False, header=False)\n",
    "test_df.to_csv(\"step16_cap_speaker_length_940h_test.txt\", sep='|', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create test set of 20 seen speakers in sachnoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>transcript</th>\n",
       "      <th>speaker</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>big_processed_data/Ngọc_Như/Thảm_Kịch_Bí_Ẩn_Ở_...</td>\n",
       "      <td>phải không? mười năm rồi, thưa ông. đó là một ...</td>\n",
       "      <td>Ngọc_Như</td>\n",
       "      <td>11.114063</td>\n",
       "      <td>0.003087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>big_processed_data/Ngọc_Như/Thảm_Kịch_Bí_Ẩn_Ở_...</td>\n",
       "      <td>ông ta cầm chiếc nón kết trên tay và lặng lẽ x...</td>\n",
       "      <td>Ngọc_Như</td>\n",
       "      <td>11.217188</td>\n",
       "      <td>0.003116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>big_processed_data/Ngọc_Như/Thảm_Kịch_Bí_Ẩn_Ở_...</td>\n",
       "      <td>ông có vẻ ăn năn đến độ tôi thấy tội nghiệp ch...</td>\n",
       "      <td>Ngọc_Như</td>\n",
       "      <td>10.590625</td>\n",
       "      <td>0.002942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>big_processed_data/Ngọc_Như/Thảm_Kịch_Bí_Ẩn_Ở_...</td>\n",
       "      <td>bà ta đang thay quần áo thì bị kinh hãi bởi ti...</td>\n",
       "      <td>Ngọc_Như</td>\n",
       "      <td>11.173438</td>\n",
       "      <td>0.003104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>big_processed_data/Ngọc_Như/Thảm_Kịch_Bí_Ẩn_Ở_...</td>\n",
       "      <td>vâng, đúng như vậy và cửa sổ thư phòng thì lại...</td>\n",
       "      <td>Ngọc_Như</td>\n",
       "      <td>10.200250</td>\n",
       "      <td>0.002833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filename  \\\n",
       "302  big_processed_data/Ngọc_Như/Thảm_Kịch_Bí_Ẩn_Ở_...   \n",
       "313  big_processed_data/Ngọc_Như/Thảm_Kịch_Bí_Ẩn_Ở_...   \n",
       "322  big_processed_data/Ngọc_Như/Thảm_Kịch_Bí_Ẩn_Ở_...   \n",
       "328  big_processed_data/Ngọc_Như/Thảm_Kịch_Bí_Ẩn_Ở_...   \n",
       "329  big_processed_data/Ngọc_Như/Thảm_Kịch_Bí_Ẩn_Ở_...   \n",
       "\n",
       "                                            transcript   speaker   duration  \\\n",
       "302  phải không? mười năm rồi, thưa ông. đó là một ...  Ngọc_Như  11.114063   \n",
       "313  ông ta cầm chiếc nón kết trên tay và lặng lẽ x...  Ngọc_Như  11.217188   \n",
       "322  ông có vẻ ăn năn đến độ tôi thấy tội nghiệp ch...  Ngọc_Như  10.590625   \n",
       "328  bà ta đang thay quần áo thì bị kinh hãi bởi ti...  Ngọc_Như  11.173438   \n",
       "329  vâng, đúng như vậy và cửa sổ thư phòng thì lại...  Ngọc_Như  10.200250   \n",
       "\n",
       "     duration_hours  \n",
       "302        0.003087  \n",
       "313        0.003116  \n",
       "322        0.002942  \n",
       "328        0.003104  \n",
       "329        0.002833  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df of samples in train_df but not in filtered_train\n",
    "diff_df = train_df.merge(filtered_train, on=['filename', 'transcript', 'speaker', 'duration', 'duration_hours'], \n",
    "                         how='left', indicator=True)\n",
    "\n",
    "# Filter rows that are only in train_df (i.e., not in filtered_train)\n",
    "left_out = diff_df[diff_df['_merge'] == 'left_only']\n",
    "\n",
    "# Drop the '_merge' column\n",
    "left_out = left_out.drop(columns=['_merge'])\n",
    "\n",
    "# Display the result\n",
    "left_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>transcript</th>\n",
       "      <th>speaker</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>big_processed_data/Ngọc_Như/Thảm_Kịch_Bí_Ẩn_Ở_...</td>\n",
       "      <td>phải không? mười năm rồi, thưa ông. đó là một ...</td>\n",
       "      <td>Ngọc_Như</td>\n",
       "      <td>11.114063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>big_processed_data/Ngọc_Như/Thảm_Kịch_Bí_Ẩn_Ở_...</td>\n",
       "      <td>ông ta cầm chiếc nón kết trên tay và lặng lẽ x...</td>\n",
       "      <td>Ngọc_Như</td>\n",
       "      <td>11.217188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>big_processed_data/Ngọc_Như/Thảm_Kịch_Bí_Ẩn_Ở_...</td>\n",
       "      <td>ông có vẻ ăn năn đến độ tôi thấy tội nghiệp ch...</td>\n",
       "      <td>Ngọc_Như</td>\n",
       "      <td>10.590625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>big_processed_data/Ngọc_Như/Thảm_Kịch_Bí_Ẩn_Ở_...</td>\n",
       "      <td>bà ta đang thay quần áo thì bị kinh hãi bởi ti...</td>\n",
       "      <td>Ngọc_Như</td>\n",
       "      <td>11.173438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>big_processed_data/Ngọc_Như/Thảm_Kịch_Bí_Ẩn_Ở_...</td>\n",
       "      <td>vâng, đúng như vậy và cửa sổ thư phòng thì lại...</td>\n",
       "      <td>Ngọc_Như</td>\n",
       "      <td>10.200250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filename  \\\n",
       "302  big_processed_data/Ngọc_Như/Thảm_Kịch_Bí_Ẩn_Ở_...   \n",
       "313  big_processed_data/Ngọc_Như/Thảm_Kịch_Bí_Ẩn_Ở_...   \n",
       "322  big_processed_data/Ngọc_Như/Thảm_Kịch_Bí_Ẩn_Ở_...   \n",
       "328  big_processed_data/Ngọc_Như/Thảm_Kịch_Bí_Ẩn_Ở_...   \n",
       "329  big_processed_data/Ngọc_Như/Thảm_Kịch_Bí_Ẩn_Ở_...   \n",
       "\n",
       "                                            transcript   speaker   duration  \n",
       "302  phải không? mười năm rồi, thưa ông. đó là một ...  Ngọc_Như  11.114063  \n",
       "313  ông ta cầm chiếc nón kết trên tay và lặng lẽ x...  Ngọc_Như  11.217188  \n",
       "322  ông có vẻ ăn năn đến độ tôi thấy tội nghiệp ch...  Ngọc_Như  10.590625  \n",
       "328  bà ta đang thay quần áo thì bị kinh hãi bởi ti...  Ngọc_Như  11.173438  \n",
       "329  vâng, đúng như vậy và cửa sổ thư phòng thì lại...  Ngọc_Như  10.200250  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the duration_hours column\n",
    "left_out.drop(columns=['duration_hours'], inplace=True)\n",
    "left_out.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>transcript</th>\n",
       "      <th>speaker</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137961</th>\n",
       "      <td>big_processed_data/Dương_Liễu/Truyện_Ngụ_Ngôn_...</td>\n",
       "      <td>lòng ghen tị của ếch nổi lên, nó ước sao trở t...</td>\n",
       "      <td>Dương_Liễu</td>\n",
       "      <td>13.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137962</th>\n",
       "      <td>big_processed_data/Dương_Liễu/Truyện_Ngụ_Ngôn_...</td>\n",
       "      <td>nếu các cháu còn cứ ở đó, thì những bụi cây ga...</td>\n",
       "      <td>Dương_Liễu</td>\n",
       "      <td>11.196875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137966</th>\n",
       "      <td>big_processed_data/Dương_Liễu/Truyện_Ngụ_Ngôn_...</td>\n",
       "      <td>thế thì đã ăn nhầm gì? chó nhà đáp. thế còn gì...</td>\n",
       "      <td>Dương_Liễu</td>\n",
       "      <td>14.577188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137967</th>\n",
       "      <td>big_processed_data/Dương_Liễu/Truyện_Ngụ_Ngôn_...</td>\n",
       "      <td>bởi vì nơi tôi uống nước còn cách xa chỗ ngài ...</td>\n",
       "      <td>Dương_Liễu</td>\n",
       "      <td>12.679063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137968</th>\n",
       "      <td>big_processed_data/Dương_Liễu/Truyện_Ngụ_Ngôn_...</td>\n",
       "      <td>thế là, con sói cắp chứa cừu non vào tận rừng ...</td>\n",
       "      <td>Dương_Liễu</td>\n",
       "      <td>13.003625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 filename  \\\n",
       "137961  big_processed_data/Dương_Liễu/Truyện_Ngụ_Ngôn_...   \n",
       "137962  big_processed_data/Dương_Liễu/Truyện_Ngụ_Ngôn_...   \n",
       "137966  big_processed_data/Dương_Liễu/Truyện_Ngụ_Ngôn_...   \n",
       "137967  big_processed_data/Dương_Liễu/Truyện_Ngụ_Ngôn_...   \n",
       "137968  big_processed_data/Dương_Liễu/Truyện_Ngụ_Ngôn_...   \n",
       "\n",
       "                                               transcript     speaker  \\\n",
       "137961  lòng ghen tị của ếch nổi lên, nó ước sao trở t...  Dương_Liễu   \n",
       "137962  nếu các cháu còn cứ ở đó, thì những bụi cây ga...  Dương_Liễu   \n",
       "137966  thế thì đã ăn nhầm gì? chó nhà đáp. thế còn gì...  Dương_Liễu   \n",
       "137967  bởi vì nơi tôi uống nước còn cách xa chỗ ngài ...  Dương_Liễu   \n",
       "137968  thế là, con sói cắp chứa cừu non vào tận rừng ...  Dương_Liễu   \n",
       "\n",
       "         duration  \n",
       "137961  13.720000  \n",
       "137962  11.196875  \n",
       "137966  14.577188  \n",
       "137967  12.679063  \n",
       "137968  13.003625  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 1: Randomly sample 20 unique speakers from left_out\n",
    "sampled_speakers = np.random.choice(left_out['speaker'].unique(), size=20, replace=False)\n",
    "\n",
    "# Step 2: Filter left_out for only the sampled speakers\n",
    "left_out_sampled = left_out[left_out['speaker'].isin(sampled_speakers)]\n",
    "\n",
    "# Step 3: Create an empty list to store the filtered rows\n",
    "filtered_rows = []\n",
    "\n",
    "# Group by speaker and accumulate duration up to 3 minutes (180 seconds)\n",
    "grouped = left_out_sampled.groupby('speaker')\n",
    "\n",
    "for speaker, group in grouped:\n",
    "    # Sort by duration in descending order to take the longer samples first\n",
    "    \n",
    "    cumulative_duration = 0\n",
    "    for idx, row in group.iterrows():\n",
    "        if cumulative_duration + row['duration'] > 180:  # 180 seconds = 3 minutes\n",
    "            break\n",
    "        filtered_rows.append(row)\n",
    "        cumulative_duration += row['duration']\n",
    "\n",
    "# Convert the filtered rows back to a DataFrame\n",
    "left_out_subset = pd.DataFrame(filtered_rows)\n",
    "\n",
    "# Display the result\n",
    "left_out_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.962697553888889"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_out_subset['duration'].sum() / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get speakers in left_out_subset\n",
    "left_out_subset_speakers = left_out_subset['speaker'].unique()\n",
    "# make sure they appear in train set (filtered_train)\n",
    "for speaker in left_out_subset_speakers:\n",
    "    assert speaker in filtered_train['speaker'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save left_out_subset to csv file\n",
    "left_out_subset.to_csv(\"sachnoi_seen_speaker_test.csv\", sep='|', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON files created in json_files_sachnoi_seen_test\n"
     ]
    }
   ],
   "source": [
    "# create json files for test set (left_out_subset)\n",
    "# each speaker = 1 json file. each json file = many samples, each sample = {path, duration, transcript}\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Define the output folder for JSON files\n",
    "json_folder = 'json_files_sachnoi_seen_test'\n",
    "os.makedirs(json_folder, exist_ok=True)  # Create the folder if it doesn't exist\n",
    "\n",
    "# Group by speaker and create a JSON file for each speaker\n",
    "grouped = left_out_subset.groupby('speaker')\n",
    "\n",
    "lustre_path = \"/lustre/scratch/client/vinai/users/thivt1/code/oneshot\"\n",
    "for speaker, group in grouped:\n",
    "    # Create a list of samples for the speaker\n",
    "    samples = []\n",
    "    for _, row in group.iterrows():\n",
    "        sample = {\n",
    "            'path': os.path.join(lustre_path, row['filename']),  # Adjust the key to match your DataFrame\n",
    "            'duration': row['duration'],\n",
    "            'transcript': row['transcript']\n",
    "        }\n",
    "        samples.append(sample)\n",
    "    \n",
    "    # Define the JSON file name\n",
    "    json_file_path = os.path.join(json_folder, f\"sachnoi-seen-{speaker}.json\")\n",
    "    \n",
    "    # Write samples to the JSON file\n",
    "    with open(json_file_path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(samples, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"JSON files created in {json_folder}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "train_path = \"sach_noi_train.json\"\n",
    "test_path = 'sach_noi_test.json'\n",
    "root_dir = \"/lustre/scratch/client/vinai/users/thivt1/code/oneshot\"\n",
    "\n",
    "# Load dialect information from JSONL file\n",
    "dialect_file = \"/lustre/scratch/client/vinai/users/thivt1/code/oneshot/data_stories_large_model.jsonl\"\n",
    "dialect_info = {}\n",
    "\n",
    "with open(dialect_file, 'r') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        dialect_info[data['path']] = data['dialect']['Label']\n",
    "\n",
    "# Function to create dictionary from DataFrame row\n",
    "def create_dict(row):\n",
    "    path = os.path.join(root_dir, row['filename'])\n",
    "    dialect = dialect_info.get(path)\n",
    "    if dialect:\n",
    "        return {\n",
    "            \"path\": path,\n",
    "            \"transcript\": row['transcript'],\n",
    "            \"speaker\": row['speaker'],\n",
    "            \"duration\": row['duration'],\n",
    "            \"dialect\": dialect,\n",
    "            \"segment_id\": get_segment_id_from_path(row['filename'])\n",
    "        }\n",
    "    else: \n",
    "        raise ValueError(f\"Dialect information not found for {path}\")\n",
    "\n",
    "def get_segment_id_from_path(path):\n",
    "    if len(path.split(\"/\")[1:]) == 3:\n",
    "        return \"___\".join(path.replace('.wav', '').split(\"/\")[1:])\n",
    "    else: \n",
    "        speaker, book, chapter, segment = path.replace('.wav', '').split(\"/\")[1:]\n",
    "        return f\"{speaker}___{chapter}___{segment}\"\n",
    "\n",
    "# Create list of dictionaries for train and test sets\n",
    "train_list = [create_dict(row) for index, row in train_df.iterrows()]\n",
    "test_list = [create_dict(row) for index, row in test_df.iterrows()]\n",
    "\n",
    "# Save to JSON files\n",
    "with open(train_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(train_list, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open(test_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(test_list, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"JSON files created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '/lustre/scratch/client/vinai/users/thivt1/code/oneshot/big_processed_data/Dương_Liễu/Truyện_Ngụ_Ngôn_La_Fontaine/truyen-ngu-1/chunk-268_82-282_44_trimmed_norm_float32.wav',\n",
       " 'duration': 13.72,\n",
       " 'transcript': 'lòng ghen tị của ếch nổi lên, nó ước sao trở thành to lớn như bò kia. nó cố gắng phình người ra, bành cổ rộng ra, hy vọng cải thiện được vóc dáng bé nhỏ của mình.'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('json_files_sachnoi_seen_test/sachnoi-seen-Dương_Liễu.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "data[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mfa2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
